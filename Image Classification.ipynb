{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333acb74",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "This notebook deals with the image classification portion of the final project. We'll be utilizing a Convolutional Neural Network from the Tensorflow framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba3ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import image\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de79a76",
   "metadata": {},
   "source": [
    "## Prepping our data\n",
    "We'll need split our images into train and test sets. To do this we'll create two new directories, train_images and test_images. We'll make a function to make theses directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14da0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFolder(subfolder):\n",
    "    parent_dir = os.getcwd()\n",
    "    path = os.path.join(parent_dir,subfolder)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "        print('Successfully made directory.')\n",
    "    except OSError as error:\n",
    "        print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c01b57e",
   "metadata": {},
   "source": [
    "Now we'll make the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614948fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\train_images'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\test_images'\n"
     ]
    }
   ],
   "source": [
    "makeFolder('train_images')\n",
    "makeFolder('test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37438a4",
   "metadata": {},
   "source": [
    "We'll create a function to copy to the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b03690eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyDir(destination):\n",
    "    current = os.getcwd()\n",
    "    for sub in ['animal_crossing','doom']:\n",
    "        try:\n",
    "            shutil.copytree(f'{current}\\\\{sub}',f'{current}\\\\{destination}\\\\{sub}')\n",
    "            print(f'Successfully copied {sub} to {destination}')\n",
    "        except OSError as error:\n",
    "            print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f46bc2",
   "metadata": {},
   "source": [
    "Now we'll copy to our directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833bfecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\train_images\\\\animal_crossing'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\train_images\\\\doom'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\test_images\\\\animal_crossing'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\test_images\\\\doom'\n"
     ]
    }
   ],
   "source": [
    "copyDir('train_images')\n",
    "copyDir('test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd802b47",
   "metadata": {},
   "source": [
    "Next we get our image file names for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b01547",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')['filename']\n",
    "test = pd.read_csv('test.csv')['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407eb75",
   "metadata": {},
   "source": [
    "Now we'll loop through our directories and remove the files not in the specified list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0784c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFilesNotInList(array,folder):\n",
    "    flist = array.tolist()\n",
    "    for sub in ['animal_crossing','doom']:\n",
    "        subpath = os.path.join(folder,sub)\n",
    "        for file in os.listdir(subpath):\n",
    "            f = os.path.join(subpath,file)\n",
    "            if file not in flist:\n",
    "                os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1d620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "removeFilesNotInList(train,'.\\\\train_images')\n",
    "removeFilesNotInList(test,'.\\\\test_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd16634",
   "metadata": {},
   "source": [
    "Now let's load our training images into tensorflow. We'll be utilizing the image_dataset_from_directory function in tensorflow. This function looks into our directory for subdirectories containing images. The subdirectory of the images will be the class that the image is assigned to. This function will also change the size of our image. This is important as all images in our model will need to be the same size. We'll also input our images as a batch size. Neural Networks are trained in batches so it's important that our datasets are trained in these batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a2ce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1276 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory('.\\\\train_images',image_size=(300,300),\n",
    "                                       batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b30af8",
   "metadata": {},
   "source": [
    "And now our testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb2605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = image_dataset_from_directory('.\\\\test_images',image_size=(300,300),\n",
    "                                       batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b04983",
   "metadata": {},
   "source": [
    "Let's assign our class names. We can use these later on to decide create a better understanding of our model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ff6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819ea7f",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "Now let's create our model. This model will have a couple of different types of layers in it. The first layer in the model rescales the images so that the model can work better. Convolutional Neural Networks ideally want to work with pixel data with a max value of 1. \n",
    "\n",
    "The 2nd type of layer we have is a convolutional 2d layer that utilizes convolutions to understand features distinctly. More explanation on convolutions can be found here: https://www.youtube.com/watch?v=KuXjwB4LzSA&t=713s&ab_channel=3Blue1Brown. \n",
    "\n",
    "The 3rd type of layer we have is a pooling layer. Pooling layers work to reduce the size of our next layer which helps with computation time. \n",
    "\n",
    "The 4th layer is simply a layer that flattens our output to reshape our layer to the desired shape. \n",
    "\n",
    "The last type of layer is a dense layer. Dense layers consist of nodes that work utilize many linear parameters to make estimations. Note the last dense layer doesn't have an activation function and contains a node for each of our classes. \n",
    "\n",
    "More info about convolutional neural networks in tensor flow can be found in the following colab notebook: https://colab.research.google.com/drive/1ZZXnCjFEOkp_KdNcNabd14yok0BAIuwS#forceEdit=true&sandboxMode=true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db4f62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Rescaling(1./255))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
    "model.add(layers.MaxPooling2D((3, 3)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3, 3)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32,activation='softmax'))\n",
    "model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1bfeb",
   "metadata": {},
   "source": [
    "Now that we have created our model framework, we need to compile and fit it. The optimizer, loss function, and metric was taken from the colab notebook referenced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3d328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "40/40 [==============================] - 33s 790ms/step - loss: 0.6592 - accuracy: 0.6379\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 33s 787ms/step - loss: 0.6090 - accuracy: 0.7265\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 33s 800ms/step - loss: 0.5897 - accuracy: 0.7453\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 33s 799ms/step - loss: 0.5843 - accuracy: 0.7453\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 33s 803ms/step - loss: 0.5617 - accuracy: 0.7688\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "history =  model.fit(train_ds,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ac946",
   "metadata": {},
   "source": [
    "Let's evaluate our performance on our test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26aaa31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 156ms/step - loss: 0.5690 - accuracy: 0.7673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5689965486526489, 0.7672955989837646]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009edef",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "Before we make predictions on our testing and training sets, let's get our files into new folders so we can loop through the file names and make predictions on our file. We need to do this because we need to have the associated file name in our output to combine this with our other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69044af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\train_images_combined'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\sulli\\\\Code\\\\Python\\\\Data Mining\\\\Final Project\\\\test_images_combined'\n"
     ]
    }
   ],
   "source": [
    "makeFolder('train_images_combined')\n",
    "makeFolder('test_images_combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5d06f",
   "metadata": {},
   "source": [
    "Let's also create a function to copy all of the contents from our image directories so that we can copy the contents correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "838a12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyFromDir(start,end):\n",
    "    for folder in os.listdir(start):\n",
    "        folder_path = os.path.join(start,folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            f = os.path.join(folder_path,file)\n",
    "            shutil.copy(f,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06712a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "copyFromDir('.\\\\train_images','.\\\\train_images_combined')\n",
    "copyFromDir('.\\\\test_images','.\\\\test_images_combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f800bc",
   "metadata": {},
   "source": [
    "Now we copy the list of each of the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1316a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = list(os.listdir(\".\\\\train_images_combined\"))\n",
    "test_files  = list(os.listdir(\".\\\\test_images_combined\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c443bc",
   "metadata": {},
   "source": [
    "Finally we'll make a prediction function for our model. This will be a little complicated as input needs to be a batch of images. This method was taken from the tensorflow documentation. https://www.tensorflow.org/api_docs/python/tf/keras/utils/load_img."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "679b95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePredFromDir(targetDir,model):\n",
    "    animal_crossing = []\n",
    "    doom = []\n",
    "    for file in os.listdir(targetDir):\n",
    "        f = os.path.join(targetDir,file)\n",
    "        image = tf.keras.utils.load_img(f,target_size=(300,300))\n",
    "        input_arr = tf.keras.utils.img_to_array(image)\n",
    "        input_arr = np.array([input_arr]) \n",
    "        predictions = model.predict(input_arr,verbose=0)\n",
    "        animal_crossing.append(predictions[0,0])\n",
    "        doom.append(predictions[0,1])\n",
    "    return([animal_crossing,doom])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00233e3e",
   "metadata": {},
   "source": [
    "Now let's make our predictions for our training set and testing set. We'll export them as csv's for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc6babb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = pd.DataFrame()\n",
    "train_predictions['File'] = train_files\n",
    "preds = makePredFromDir(\".\\\\train_images_combined\",model)\n",
    "train_predictions['AnimalCrossingWeights']= preds[0]\n",
    "train_predictions['DoomWeights'] = preds[1]\n",
    "train_predictions.to_csv('TrainPred.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "642d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame()\n",
    "test_predictions['File'] = test_files\n",
    "preds = makePredFromDir(\".\\\\test_images_combined\",model)\n",
    "test_predictions['AnimalCrossingWeights']= preds[0]\n",
    "test_predictions['DoomWeights'] = preds[1]\n",
    "test_predictions.to_csv('TestPred.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7606aa2",
   "metadata": {},
   "source": [
    "The last thing we want to do is delete the copied directories as they take up space on our devices. I only have one TB of storage on my machine so I want to preserve this space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "765ec8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\".\\\\train_images_combined\")\n",
    "shutil.rmtree(\".\\\\test_images_combined\" )\n",
    "shutil.rmtree(\".\\\\train_images\")\n",
    "shutil.rmtree(\".\\\\test_images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
